{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MP-100 CAPE Training on Google Colab\n",
        "\n",
        "This notebook trains Category-Agnostic Pose Estimation (CAPE) on the MP-100 dataset using Google Colab's GPU.\n",
        "\n",
        "## Setup Instructions\n",
        "1. Enable GPU: Runtime → Change runtime type → GPU (T4 or better)\n",
        "2. Run all cells in order\n",
        "3. The notebook will:\n",
        "   - Clone code from GitHub\n",
        "   - Install dependencies\n",
        "   - Authenticate to GCP\n",
        "   - Mount GCS bucket with data\n",
        "   - Run training with \"tiny\" mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected! Please enable GPU in Runtime > Change runtime type > GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository from GitHub\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "REPO_URL = \"https://github.com/nkkrnkl/category-agnostic-pose-estimation.git\"\n",
        "BRANCH = \"teo-branch-copy\"\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    print(f\"Removing existing directory: {PROJECT_ROOT}\")\n",
        "    !rm -rf {PROJECT_ROOT}\n",
        "\n",
        "# For private repositories, you need to authenticate\n",
        "# Option 1: Use Personal Access Token (recommended)\n",
        "# Get token from: https://github.com/settings/tokens\n",
        "# Create a token with 'repo' scope\n",
        "print(\"For private repositories, you need to authenticate.\")\n",
        "print(\"Option 1: Enter your GitHub Personal Access Token\")\n",
        "print(\"  (Get one from: https://github.com/settings/tokens)\")\n",
        "print(\"Option 2: Press Enter to try without token (will fail if repo is private)\")\n",
        "print()\n",
        "\n",
        "GITHUB_TOKEN = getpass(\"Enter GitHub Personal Access Token (or press Enter to skip): \")\n",
        "\n",
        "if GITHUB_TOKEN.strip():\n",
        "    # Use token in URL\n",
        "    # Format: https://TOKEN@github.com/username/repo.git\n",
        "    AUTH_REPO_URL = REPO_URL.replace(\"https://github.com/\", f\"https://{GITHUB_TOKEN}@github.com/\")\n",
        "    print(f\"Cloning repository from {REPO_URL} (branch: {BRANCH})...\")\n",
        "    !git clone -b {BRANCH} {AUTH_REPO_URL} {PROJECT_ROOT}\n",
        "else:\n",
        "    # Try without token (will work if repo is public)\n",
        "    print(f\"Cloning repository from {REPO_URL} (branch: {BRANCH})...\")\n",
        "    !git clone -b {BRANCH} {REPO_URL} {PROJECT_ROOT}\n",
        "\n",
        "# Verify clone\n",
        "if os.path.exists(PROJECT_ROOT) and os.path.exists(os.path.join(PROJECT_ROOT, \".git\")):\n",
        "    print(f\"✅ Repository cloned successfully to {PROJECT_ROOT}\")\n",
        "    !cd {PROJECT_ROOT} && git branch\n",
        "else:\n",
        "    print(\"❌ Failed to clone repository\")\n",
        "    print(\"\\nIf the repository is private, you need to:\")\n",
        "    print(\"1. Create a Personal Access Token at: https://github.com/settings/tokens\")\n",
        "    print(\"2. Select 'repo' scope\")\n",
        "    print(\"3. Run this cell again and paste the token when prompted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clone repository from GitHub\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/nkkrnkl/category-agnostic-pose-estimation.git\"\n",
        "BRANCH = \"teo-branch-copy\"\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    print(f\"Removing existing directory: {PROJECT_ROOT}\")\n",
        "    !rm -rf {PROJECT_ROOT}\n",
        "\n",
        "# Clone the repository\n",
        "print(f\"Cloning repository from {REPO_URL} (branch: {BRANCH})...\")\n",
        "!git clone -b {BRANCH} {REPO_URL} {PROJECT_ROOT}\n",
        "\n",
        "# Verify clone\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    print(f\"✅ Repository cloned successfully to {PROJECT_ROOT}\")\n",
        "    !cd {PROJECT_ROOT} && git branch\n",
        "else:\n",
        "    print(\"❌ Failed to clone repository\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install additional dependencies needed for plot_utils and other utilities\n",
        "# (descartes, shapely, etc. - these are in requirements.txt but not requirements_cape.txt)\n",
        "print(\"Installing additional dependencies (descartes, shapely, etc.)...\")\n",
        "!pip install -q descartes shapely>=1.8.0\n",
        "print(\"✅ Additional dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "REQUIREMENTS_FILE = os.path.join(PROJECT_ROOT, \"requirements_cape.txt\")\n",
        "\n",
        "print(\"Installing requirements from requirements_cape.txt...\")\n",
        "!cd {PROJECT_ROOT} && pip install -q -r {REQUIREMENTS_FILE}\n",
        "\n",
        "# Install detectron2 for CUDA 11.8 (Colab typically has CUDA 11.8)\n",
        "print(\"\\nInstalling detectron2...\")\n",
        "!pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "print(\"✅ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Authenticate to GCP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate to GCP\n",
        "from google.colab import auth\n",
        "\n",
        "print(\"Authenticating to GCP...\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set GCP project\n",
        "GCP_PROJECT = \"dl-category-agnostic-pose-est\"\n",
        "!gcloud config set project {GCP_PROJECT}\n",
        "\n",
        "print(f\"✅ Authenticated to GCP project: {GCP_PROJECT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Mount GCS Bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data access before training\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
        "\n",
        "print(\"Verifying data access...\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Exists: {os.path.exists(DATA_DIR)}\")\n",
        "print(f\"Is symlink: {os.path.islink(DATA_DIR)}\")\n",
        "\n",
        "if os.path.exists(DATA_DIR):\n",
        "    # Check if we can list directories\n",
        "    try:\n",
        "        categories = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
        "        print(f\"✅ Found {len(categories)} category directories\")\n",
        "        if len(categories) > 0:\n",
        "            print(f\"   First 5 categories: {categories[:5]}\")\n",
        "            \n",
        "            # Try to access a file in the first category\n",
        "            first_cat = categories[0]\n",
        "            cat_dir = os.path.join(DATA_DIR, first_cat)\n",
        "            files = [f for f in os.listdir(cat_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "            if len(files) > 0:\n",
        "                test_file = os.path.join(cat_dir, files[0])\n",
        "                print(f\"   Test file exists: {os.path.exists(test_file)}\")\n",
        "                print(f\"   Test file: {test_file}\")\n",
        "            else:\n",
        "                print(f\"   ⚠️  No image files found in {first_cat}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error accessing data directory: {e}\")\n",
        "        print(\"   This might indicate the GCS mount is not working properly\")\n",
        "else:\n",
        "    print(f\"❌ Data directory does not exist: {DATA_DIR}\")\n",
        "    print(\"   Please check:\")\n",
        "    print(\"   1. GCS bucket is mounted\")\n",
        "    print(\"   2. Data symlink is created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount GCS bucket using gcsfuse\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "BUCKET_NAME = \"dl-category-agnostic-pose-mp100-data\"\n",
        "MOUNT_POINT = os.path.join(PROJECT_ROOT, \"Raster2Seq_internal-main\", \"data\")\n",
        "\n",
        "# Install gcsfuse if not already installed\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq gcsfuse\n",
        "\n",
        "# Create mount point directory\n",
        "os.makedirs(MOUNT_POINT, exist_ok=True)\n",
        "\n",
        "# Mount the bucket\n",
        "print(f\"Mounting gs://{BUCKET_NAME} to {MOUNT_POINT}...\")\n",
        "!gcsfuse --implicit-dirs {BUCKET_NAME} {MOUNT_POINT}\n",
        "\n",
        "# Verify mount\n",
        "if os.path.exists(MOUNT_POINT):\n",
        "    print(f\"✅ GCS bucket mounted successfully!\")\n",
        "    print(f\"Mount point: {MOUNT_POINT}\")\n",
        "    # List a few items to verify\n",
        "    !ls {MOUNT_POINT} | head -10\n",
        "else:\n",
        "    print(\"❌ Failed to mount GCS bucket\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create Data Symlink\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create symlink from data to mounted GCS bucket (as expected by START_TRAINING.sh)\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "MOUNTED_DATA = os.path.join(PROJECT_ROOT, \"Raster2Seq_internal-main\", \"data\")\n",
        "DATA_SYMLINK = os.path.join(PROJECT_ROOT, \"data\")\n",
        "\n",
        "# Remove existing symlink or directory if it exists\n",
        "if os.path.exists(DATA_SYMLINK):\n",
        "    if os.path.islink(DATA_SYMLINK):\n",
        "        os.unlink(DATA_SYMLINK)\n",
        "    else:\n",
        "        print(f\"Warning: {DATA_SYMLINK} exists and is not a symlink\")\n",
        "\n",
        "# Create symlink\n",
        "if os.path.exists(MOUNTED_DATA):\n",
        "    os.symlink(MOUNTED_DATA, DATA_SYMLINK)\n",
        "    print(f\"✅ Created symlink: {DATA_SYMLINK} -> {MOUNTED_DATA}\")\n",
        "else:\n",
        "    print(f\"⚠️  Mounted data not found at {MOUNTED_DATA}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Run Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run training using START_TRAINING.sh with \"tiny\" mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run START_TRAINING.sh with \"tiny\" mode\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "TRAINING_SCRIPT = os.path.join(PROJECT_ROOT, \"START_TRAINING.sh\")\n",
        "\n",
        "# Make script executable\n",
        "!chmod +x {TRAINING_SCRIPT}\n",
        "\n",
        "# Change to project directory and run training\n",
        "print(\"Starting training with 'tiny' mode...\")\n",
        "print(\"This will run 5 epochs with batch_size 8 (~30-60 min)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "!cd {PROJECT_ROOT} && bash {TRAINING_SCRIPT} tiny\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Monitor Training (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check training logs\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"output\", \"tiny_test\", \"tiny_test\")\n",
        "LOG_FILE = os.path.join(OUTPUT_DIR, \"log.txt\")\n",
        "\n",
        "if os.path.exists(LOG_FILE):\n",
        "    print(f\"Reading log file: {LOG_FILE}\")\n",
        "    with open(LOG_FILE, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        print(f\"Total log entries: {len(lines)}\")\n",
        "        if lines:\n",
        "            print(\"\\nLast 3 entries:\")\n",
        "            for line in lines[-3:]:\n",
        "                try:\n",
        "                    stats = json.loads(line.strip())\n",
        "                    print(f\"  Epoch {stats.get('epoch', 'N/A')}: \")\n",
        "                    print(f\"    Train Loss: {stats.get('train_loss', stats.get('loss', 'N/A'))}\")\n",
        "                    print(f\"    Val Loss: {stats.get('test_loss', 'N/A')}\")\n",
        "                except:\n",
        "                    pass\n",
        "else:\n",
        "    print(f\"Log file not found: {LOG_FILE}\")\n",
        "    print(\"\\nAvailable output directories:\")\n",
        "    output_base = os.path.join(PROJECT_ROOT, \"output\")\n",
        "    if os.path.exists(output_base):\n",
        "        for d in os.listdir(output_base):\n",
        "            print(f\"  - {os.path.join(output_base, d)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Download Results (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download checkpoints and logs\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "OUTPUT_BASE = os.path.join(PROJECT_ROOT, \"output\")\n",
        "\n",
        "# Find all checkpoints\n",
        "checkpoints = list(Path(OUTPUT_BASE).rglob(\"checkpoint*.pth\"))\n",
        "\n",
        "if checkpoints:\n",
        "    print(f\"Found {len(checkpoints)} checkpoint(s)\")\n",
        "    \n",
        "    # Create zip with all checkpoints\n",
        "    zip_path = \"/content/checkpoints.zip\"\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for cp in checkpoints:\n",
        "            # Preserve relative path structure\n",
        "            rel_path = os.path.relpath(cp, PROJECT_ROOT)\n",
        "            zipf.write(cp, rel_path)\n",
        "    \n",
        "    print(f\"\\nDownloading {zip_path}...\")\n",
        "    files.download(zip_path)\n",
        "    print(\"✅ Download complete!\")\n",
        "else:\n",
        "    print(\"No checkpoints found yet.\")\n",
        "    print(f\"Output directory: {OUTPUT_BASE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
