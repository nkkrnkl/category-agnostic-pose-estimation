{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MP-100 CAPE Training on Google Colab\n",
        "\n",
        "This notebook trains Category-Agnostic Pose Estimation (CAPE) on the MP-100 dataset using Google Colab's GPU.\n",
        "\n",
        "## Setup Instructions\n",
        "1. Enable GPU: Runtime → Change runtime type → GPU (T4 or better)\n",
        "2. Run all cells in order\n",
        "3. The notebook will:\n",
        "   - Clone code from GitHub\n",
        "   - Install dependencies\n",
        "   - Authenticate to GCP\n",
        "   - Mount GCS bucket with data\n",
        "   - Run training with \"tiny\" mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Check GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected! Please enable GPU in Runtime > Change runtime type > GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository from GitHub\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "REPO_URL = \"https://github.com/nkkrnkl/category-agnostic-pose-estimation.git\"\n",
        "BRANCH = \"teo-branch-copy\"\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "\n",
        "# Remove existing directory if it exists\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    print(f\"Removing existing directory: {PROJECT_ROOT}\")\n",
        "    !rm -rf {PROJECT_ROOT}\n",
        "\n",
        "# For private repositories, you need to authenticate\n",
        "# Option 1: Use Personal Access Token (recommended)\n",
        "# Get token from: https://github.com/settings/tokens\n",
        "# Create a token with 'repo' scope\n",
        "print(\"For private repositories, you need to authenticate.\")\n",
        "print(\"Option 1: Enter your GitHub Personal Access Token\")\n",
        "print(\"  (Get one from: https://github.com/settings/tokens)\")\n",
        "print(\"Option 2: Press Enter to try without token (will fail if repo is private)\")\n",
        "print()\n",
        "\n",
        "GITHUB_TOKEN = getpass(\"Enter GitHub Personal Access Token (or press Enter to skip): \")\n",
        "\n",
        "if GITHUB_TOKEN.strip():\n",
        "    # Use token in URL\n",
        "    # Format: https://TOKEN@github.com/username/repo.git\n",
        "    AUTH_REPO_URL = REPO_URL.replace(\"https://github.com/\", f\"https://{GITHUB_TOKEN}@github.com/\")\n",
        "    print(f\"Cloning repository from {REPO_URL} (branch: {BRANCH})...\")\n",
        "    !git clone -b {BRANCH} {AUTH_REPO_URL} {PROJECT_ROOT}\n",
        "else:\n",
        "    # Try without token (will work if repo is public)\n",
        "    print(f\"Cloning repository from {REPO_URL} (branch: {BRANCH})...\")\n",
        "    !git clone -b {BRANCH} {REPO_URL} {PROJECT_ROOT}\n",
        "\n",
        "# Verify clone\n",
        "if os.path.exists(PROJECT_ROOT) and os.path.exists(os.path.join(PROJECT_ROOT, \".git\")):\n",
        "    print(f\"✅ Repository cloned successfully to {PROJECT_ROOT}\")\n",
        "    !cd {PROJECT_ROOT} && git branch\n",
        "else:\n",
        "    print(\"❌ Failed to clone repository\")\n",
        "    print(\"\\nIf the repository is private, you need to:\")\n",
        "    print(\"1. Create a Personal Access Token at: https://github.com/settings/tokens\")\n",
        "    print(\"2. Select 'repo' scope\")\n",
        "    print(\"3. Run this cell again and paste the token when prompted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install additional dependencies needed for plot_utils and other utilities\n",
        "# (descartes, shapely, etc. - these are in requirements.txt but not requirements_cape.txt)\n",
        "print(\"Installing additional dependencies (descartes, shapely, etc.)...\")\n",
        "!pip install -q descartes shapely>=1.8.0\n",
        "print(\"✅ Additional dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "REQUIREMENTS_FILE = os.path.join(PROJECT_ROOT, \"requirements_cape.txt\")\n",
        "\n",
        "print(\"Installing requirements from requirements_cape.txt...\")\n",
        "!cd {PROJECT_ROOT} && pip install -q -r {REQUIREMENTS_FILE}\n",
        "\n",
        "# Install detectron2 for CUDA 11.8 (Colab typically has CUDA 11.8)\n",
        "print(\"\\nInstalling detectron2...\")\n",
        "!pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "print(\"✅ All dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Authenticate to GCP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Authenticate to GCP\n",
        "from google.colab import auth\n",
        "\n",
        "print(\"Authenticating to GCP...\")\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set GCP project\n",
        "GCP_PROJECT = \"dl-category-agnostic-pose-est\"\n",
        "!gcloud config set project {GCP_PROJECT}\n",
        "\n",
        "print(f\"✅ Authenticated to GCP project: {GCP_PROJECT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Mount GCS Bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data access before training\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
        "\n",
        "print(\"Verifying data access...\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Exists: {os.path.exists(DATA_DIR)}\")\n",
        "print(f\"Is symlink: {os.path.islink(DATA_DIR)}\")\n",
        "\n",
        "if os.path.exists(DATA_DIR):\n",
        "    # Check if we can list directories\n",
        "    try:\n",
        "        categories = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
        "        print(f\"✅ Found {len(categories)} category directories\")\n",
        "        if len(categories) > 0:\n",
        "            print(f\"   First 5 categories: {categories[:5]}\")\n",
        "            \n",
        "            # Try to access a file in the first category\n",
        "            first_cat = categories[0]\n",
        "            cat_dir = os.path.join(DATA_DIR, first_cat)\n",
        "            files = [f for f in os.listdir(cat_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "            if len(files) > 0:\n",
        "                test_file = os.path.join(cat_dir, files[0])\n",
        "                print(f\"   Test file exists: {os.path.exists(test_file)}\")\n",
        "                print(f\"   Test file: {test_file}\")\n",
        "            else:\n",
        "                print(f\"   ⚠️  No image files found in {first_cat}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error accessing data directory: {e}\")\n",
        "        print(\"   This might indicate the GCS mount is not working properly\")\n",
        "else:\n",
        "    print(f\"❌ Data directory does not exist: {DATA_DIR}\")\n",
        "    print(\"   Please check:\")\n",
        "    print(\"   1. GCS bucket is mounted\")\n",
        "    print(\"   2. Data symlink is created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount GCS bucket using gcsfuse\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "BUCKET_NAME = \"dl-category-agnostic-pose-mp100-data\"\n",
        "MOUNT_POINT = os.path.join(PROJECT_ROOT, \"Raster2Seq_internal-main\", \"data\")\n",
        "\n",
        "# Install gcsfuse from Google's official repository\n",
        "print(\"Installing gcsfuse...\")\n",
        "# Add Google's gcsfuse repository (updated method for newer Ubuntu versions)\n",
        "!export GCSFUSE_REPO=gcsfuse-`lsb_release -c -s` && \\\n",
        "echo \"deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list && \\\n",
        "curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg && \\\n",
        "echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt $GCSFUSE_REPO main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list && \\\n",
        "sudo apt-get update && \\\n",
        "sudo apt-get install -y gcsfuse\n",
        "\n",
        "# Verify installation\n",
        "!which gcsfuse\n",
        "print(\"✅ gcsfuse installed\")\n",
        "\n",
        "# Create mount point directory and parent directories\n",
        "print(f\"Creating mount point: {MOUNT_POINT}\")\n",
        "os.makedirs(os.path.dirname(MOUNT_POINT), exist_ok=True)\n",
        "os.makedirs(MOUNT_POINT, exist_ok=True)\n",
        "\n",
        "# Check if already mounted\n",
        "try:\n",
        "    result = subprocess.run(['mountpoint', '-q', MOUNT_POINT], capture_output=True)\n",
        "    if result.returncode == 0:\n",
        "        print(f\"✅ Already mounted at {MOUNT_POINT}\")\n",
        "    else:\n",
        "        # Try to unmount if exists but not properly mounted\n",
        "        try:\n",
        "            subprocess.run(['fusermount', '-u', MOUNT_POINT], capture_output=True, timeout=5)\n",
        "        except:\n",
        "            try:\n",
        "                subprocess.run(['umount', MOUNT_POINT], capture_output=True, timeout=5)\n",
        "            except:\n",
        "                pass\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Mount the bucket\n",
        "print(f\"Mounting gs://{BUCKET_NAME} to {MOUNT_POINT}...\")\n",
        "print(\"This may take a moment...\")\n",
        "\n",
        "# Run gcsfuse in background\n",
        "# Note: In Colab, we need to run gcsfuse in background using shell &\n",
        "print(f\"Running: gcsfuse --implicit-dirs {BUCKET_NAME} {MOUNT_POINT}\")\n",
        "!nohup gcsfuse --implicit-dirs {BUCKET_NAME} {MOUNT_POINT} > /tmp/gcsfuse.log 2>&1 &\n",
        "\n",
        "# Wait a moment for mount to initialize\n",
        "print(\"Waiting for mount to initialize...\")\n",
        "time.sleep(8)  # Give it more time to mount\n",
        "\n",
        "# Check mount status\n",
        "print(\"\\nChecking mount status...\")\n",
        "# Check mount log for errors\n",
        "if os.path.exists(\"/tmp/gcsfuse.log\"):\n",
        "    with open(\"/tmp/gcsfuse.log\", \"r\") as f:\n",
        "        log_content = f.read()\n",
        "        if log_content:\n",
        "            print(\"Mount log:\")\n",
        "            print(log_content[-500:])  # Last 500 chars\n",
        "        else:\n",
        "            print(\"Mount log is empty (mount might still be initializing)\")\n",
        "\n",
        "# Also verify we can access the bucket directly with gsutil\n",
        "print(\"\\nVerifying bucket access with gsutil...\")\n",
        "!gsutil ls gs://{BUCKET_NAME}/ | head -10\n",
        "\n",
        "# Verify mount\n",
        "print(f\"\\nVerifying mount at: {MOUNT_POINT}\")\n",
        "print(f\"Path exists: {os.path.exists(MOUNT_POINT)}\")\n",
        "\n",
        "# Check if actually mounted using mountpoint command\n",
        "try:\n",
        "    result = subprocess.run(['mountpoint', '-q', MOUNT_POINT], capture_output=True)\n",
        "    is_mounted = (result.returncode == 0)\n",
        "    print(f\"Is mounted: {is_mounted}\")\n",
        "except:\n",
        "    # Fallback: check mount table\n",
        "    result = subprocess.run(['mount'], capture_output=True, text=True)\n",
        "    is_mounted = MOUNT_POINT in result.stdout\n",
        "    print(f\"Is mounted (from mount table): {is_mounted}\")\n",
        "\n",
        "if os.path.exists(MOUNT_POINT) and is_mounted:\n",
        "    try:\n",
        "        # Try to list contents\n",
        "        items = os.listdir(MOUNT_POINT)\n",
        "        if len(items) > 0:\n",
        "            print(f\"✅ GCS bucket mounted successfully!\")\n",
        "            print(f\"Mount point: {MOUNT_POINT}\")\n",
        "            print(f\"Found {len(items)} items in bucket\")\n",
        "            # List a few items to verify\n",
        "            for item in items[:10]:\n",
        "                item_path = os.path.join(MOUNT_POINT, item)\n",
        "                item_type = \"directory\" if os.path.isdir(item_path) else \"file\"\n",
        "                print(f\"   - {item} ({item_type})\")\n",
        "        else:\n",
        "            print(f\"⚠️  Mount point exists but is empty (0 items)\")\n",
        "            print(f\"   This might indicate:\")\n",
        "            print(f\"   1. Bucket is empty\")\n",
        "            print(f\"   2. Mount didn't work correctly\")\n",
        "            print(f\"   3. Permission issues\")\n",
        "    except PermissionError as e:\n",
        "        print(f\"⚠️  Permission error accessing mount: {e}\")\n",
        "        print(\"   Mount might still be initializing, wait a moment and try again\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Mount point exists but cannot list contents: {e}\")\n",
        "        print(\"   This might indicate a mount issue\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "elif os.path.exists(MOUNT_POINT) and not is_mounted:\n",
        "    print(f\"⚠️  Directory exists but is not mounted\")\n",
        "    print(f\"   The directory exists but gcsfuse mount is not active\")\n",
        "    print(f\"   Trying to mount again...\")\n",
        "    # Try mounting again\n",
        "    !nohup gcsfuse --implicit-dirs {BUCKET_NAME} {MOUNT_POINT} > /tmp/gcsfuse.log 2>&1 &\n",
        "    time.sleep(5)\n",
        "    # Re-check\n",
        "    items = os.listdir(MOUNT_POINT) if os.path.exists(MOUNT_POINT) else []\n",
        "    if len(items) > 0:\n",
        "        print(f\"✅ Mount successful after retry! Found {len(items)} items\")\n",
        "    else:\n",
        "        print(f\"❌ Mount still not working\")\n",
        "else:\n",
        "    print(\"❌ Failed to mount GCS bucket\")\n",
        "    print(f\"   Mount point: {MOUNT_POINT}\")\n",
        "    print(f\"   Check:\")\n",
        "    print(f\"   1. GCP authentication (run the GCP auth cell)\")\n",
        "    print(f\"   2. Bucket name is correct: {BUCKET_NAME}\")\n",
        "    print(f\"   3. You have read access to the bucket\")\n",
        "    print(f\"   4. Check mount log: /tmp/gcsfuse.log\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create Data Symlink\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create symlink from data to mounted GCS bucket (as expected by START_TRAINING.sh)\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "MOUNTED_DATA = os.path.join(PROJECT_ROOT, \"Raster2Seq_internal-main\", \"data\")\n",
        "DATA_SYMLINK = os.path.join(PROJECT_ROOT, \"data\")\n",
        "\n",
        "print(f\"Checking mount point: {MOUNTED_DATA}\")\n",
        "print(f\"  Exists: {os.path.exists(MOUNTED_DATA)}\")\n",
        "if os.path.exists(MOUNTED_DATA):\n",
        "    print(f\"  Is directory: {os.path.isdir(MOUNTED_DATA)}\")\n",
        "    try:\n",
        "        items = os.listdir(MOUNTED_DATA)\n",
        "        print(f\"  Can list contents: Yes ({len(items)} items)\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Can list contents: No ({e})\")\n",
        "\n",
        "# Remove existing symlink or directory if it exists\n",
        "if os.path.exists(DATA_SYMLINK):\n",
        "    if os.path.islink(DATA_SYMLINK):\n",
        "        print(f\"Removing existing symlink: {DATA_SYMLINK}\")\n",
        "        os.unlink(DATA_SYMLINK)\n",
        "    elif os.path.isdir(DATA_SYMLINK):\n",
        "        print(f\"Warning: {DATA_SYMLINK} exists as a directory (not a symlink)\")\n",
        "        print(\"   Removing it to create symlink...\")\n",
        "        import shutil\n",
        "        shutil.rmtree(DATA_SYMLINK)\n",
        "    else:\n",
        "        print(f\"Warning: {DATA_SYMLINK} exists and is not a symlink or directory\")\n",
        "        os.remove(DATA_SYMLINK)\n",
        "\n",
        "# Create symlink\n",
        "if os.path.exists(MOUNTED_DATA) and os.path.isdir(MOUNTED_DATA):\n",
        "    try:\n",
        "        # Use absolute path for symlink target\n",
        "        MOUNTED_DATA_ABS = os.path.abspath(MOUNTED_DATA)\n",
        "        print(f\"\\nCreating symlink:\")\n",
        "        print(f\"  From: {DATA_SYMLINK}\")\n",
        "        print(f\"  To: {MOUNTED_DATA_ABS}\")\n",
        "        os.symlink(MOUNTED_DATA_ABS, DATA_SYMLINK)\n",
        "        print(f\"✅ Created symlink: {DATA_SYMLINK} -> {MOUNTED_DATA_ABS}\")\n",
        "        \n",
        "        # Verify symlink\n",
        "        if os.path.exists(DATA_SYMLINK):\n",
        "            print(f\"✅ Symlink verified: {DATA_SYMLINK}\")\n",
        "            print(f\"  Is symlink: {os.path.islink(DATA_SYMLINK)}\")\n",
        "            # Try to list contents through symlink\n",
        "            try:\n",
        "                items = os.listdir(DATA_SYMLINK)\n",
        "                print(f\"✅ Can access {len(items)} items through symlink\")\n",
        "                print(f\"   First 5 items: {items[:5]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  Symlink exists but cannot access contents: {e}\")\n",
        "        else:\n",
        "            print(f\"❌ Symlink creation failed - path does not exist after creation\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating symlink: {e}\")\n",
        "        print(f\"   Source: {MOUNTED_DATA}\")\n",
        "        print(f\"   Target: {DATA_SYMLINK}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(f\"❌ Mounted data not found at {MOUNTED_DATA}\")\n",
        "    print(f\"   Please check that GCS bucket is mounted correctly\")\n",
        "    print(f\"   Run the mount cell above and check for errors\")\n",
        "    print(f\"   Mount point should exist and be accessible\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Run Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run training using START_TRAINING.sh with \"tiny\" mode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run START_TRAINING.sh with \"tiny\" mode\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "TRAINING_SCRIPT = os.path.join(PROJECT_ROOT, \"START_TRAINING.sh\")\n",
        "\n",
        "# Make script executable\n",
        "!chmod +x {TRAINING_SCRIPT}\n",
        "\n",
        "# Change to project directory and run training\n",
        "print(\"Starting training with 'tiny' mode...\")\n",
        "print(\"This will run 5 epochs with batch_size 8 (~30-60 min)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "!cd {PROJECT_ROOT} && bash {TRAINING_SCRIPT} tiny\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Monitor Training (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check training logs\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "OUTPUT_DIR = os.path.join(PROJECT_ROOT, \"output\", \"tiny_test\", \"tiny_test\")\n",
        "LOG_FILE = os.path.join(OUTPUT_DIR, \"log.txt\")\n",
        "\n",
        "if os.path.exists(LOG_FILE):\n",
        "    print(f\"Reading log file: {LOG_FILE}\")\n",
        "    with open(LOG_FILE, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        print(f\"Total log entries: {len(lines)}\")\n",
        "        if lines:\n",
        "            print(\"\\nLast 3 entries:\")\n",
        "            for line in lines[-3:]:\n",
        "                try:\n",
        "                    stats = json.loads(line.strip())\n",
        "                    print(f\"  Epoch {stats.get('epoch', 'N/A')}: \")\n",
        "                    print(f\"    Train Loss: {stats.get('train_loss', stats.get('loss', 'N/A'))}\")\n",
        "                    print(f\"    Val Loss: {stats.get('test_loss', 'N/A')}\")\n",
        "                except:\n",
        "                    pass\n",
        "else:\n",
        "    print(f\"Log file not found: {LOG_FILE}\")\n",
        "    print(\"\\nAvailable output directories:\")\n",
        "    output_base = os.path.join(PROJECT_ROOT, \"output\")\n",
        "    if os.path.exists(output_base):\n",
        "        for d in os.listdir(output_base):\n",
        "            print(f\"  - {os.path.join(output_base, d)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Download Results (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download checkpoints and logs\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/category-agnostic-pose-estimation\"\n",
        "OUTPUT_BASE = os.path.join(PROJECT_ROOT, \"output\")\n",
        "\n",
        "# Find all checkpoints\n",
        "checkpoints = list(Path(OUTPUT_BASE).rglob(\"checkpoint*.pth\"))\n",
        "\n",
        "if checkpoints:\n",
        "    print(f\"Found {len(checkpoints)} checkpoint(s)\")\n",
        "    \n",
        "    # Create zip with all checkpoints\n",
        "    zip_path = \"/content/checkpoints.zip\"\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "        for cp in checkpoints:\n",
        "            # Preserve relative path structure\n",
        "            rel_path = os.path.relpath(cp, PROJECT_ROOT)\n",
        "            zipf.write(cp, rel_path)\n",
        "    \n",
        "    print(f\"\\nDownloading {zip_path}...\")\n",
        "    files.download(zip_path)\n",
        "    print(\"✅ Download complete!\")\n",
        "else:\n",
        "    print(\"No checkpoints found yet.\")\n",
        "    print(f\"Output directory: {OUTPUT_BASE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
