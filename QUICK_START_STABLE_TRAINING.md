# Quick Start: Stable Training & Evaluation

## ğŸ¯ Problem Solved

Your training showed **20-30% PCK oscillations** between epochs, making it impossible to track progress or detect overfitting.

**Root cause:** Too few validation episodes (50) + random sampling each epoch.

---

## âœ… Solution Implemented

All the improvements you requested are now complete:

1. âœ… **Configurable validation episodes** (`--val_episodes_per_epoch`)
2. âœ… **Fixed validation set mode** (`--fixed_val_episodes`, `--val_seed`)
3. âœ… **Reproducible evaluation** (`--eval_seed`)
4. âœ… **5-epoch moving average** (automatic in logs)
5. âœ… **Comprehensive documentation** (`docs/validation_stability.md`)

---

## ğŸš€ How to Use (Quick Commands)

### Start New Training (Recommended Settings)

```bash
python models/train_cape_episodic.py \
    --val_episodes_per_epoch 200 \
    --fixed_val_episodes \
    --val_seed 42 \
    --lr 5e-5 \
    --lr_drop 50 100 \
    --epochs 120 \
    --output_dir outputs/stable_training
```

**What you'll see:**
```
âœ“ Pre-generating 200 fixed episodes for val split (stable curves)...
âœ“ Cached 200 episodes

Epoch 10 Summary:
================================================================================
  Val episodes: 200 (x2 queries = 400 samples)
  Val Loss (final layer):     1.1234
  Val Loss (5-epoch MA):      1.1567    â† Smoothed trend

  Val PCK@0.2:                45.23%
  Val PCK@0.2 (5-epoch MA):   47.81%    â† True progress (trust this!)
```

---

### Evaluate Checkpoint (Reproducible)

```bash
python scripts/eval_cape_checkpoint.py \
    --checkpoint outputs/test_geometric/checkpoint_e011_lr1e-04_bs2_acc4_qpe2.pth \
    --num-episodes 200 \
    --eval_seed 123 \
    --split val \
    --num-visualizations 50 \
    --output-dir outputs/eval_e011
```

**Guaranteed:** Run it twice with same `--eval_seed` â†’ identical PCK every time.

---

### Compare Multiple Checkpoints (Fair Comparison)

```bash
# Evaluate epochs 50, 75, 100 with same seed for fair comparison
for epoch in 050 075 100; do
    python scripts/eval_cape_checkpoint.py \
        --checkpoint outputs/stable_training/checkpoint_e${epoch}_*.pth \
        --num-episodes 200 \
        --eval_seed 42 \
        --split val
done
```

---

## ğŸ“Š Expected Results

### Before (Your Current Training)

```
Epoch   Val PCK    (Oscillations)
81      62.71%     â† Peak
82      38.09%     â† Dropped 24% in 1 epoch! ğŸ˜±
83      51.23%
...
86      65.57%     â† Another peak
88      37.24%     â† Dropped 28% in 2 epochs! ğŸ˜±
```

**Problem:** Impossible to tell if model is improving!

---

### After (With New Settings)

```
Epoch   Val PCK    5-epoch MA    (Stable!)
81      52.3%      50.1%
82      51.8%      51.2%         â† Smooth upward trend
83      53.1%      51.8%
84      54.2%      52.4%
85      55.1%      53.3%
86      56.3%      54.5%
```

**Result:** Clear learning progress, reliable metrics! âœ¨

---

## ğŸ” What Changed

### 1. More Validation Samples

- **Old:** 50 episodes Ã— 2 queries = 100 samples (too few!)
- **New:** 200 episodes Ã— 2 queries = 400 samples (stable)

### 2. Fixed Validation Set

- **Old:** Different random episodes each epoch â†’ high variance
- **New:** Same 200 episodes every epoch â†’ direct comparison

### 3. Moving Average

- **New:** 5-epoch MA automatically shown in logs â†’ filters noise
- **Trust this** more than single-epoch PCK!

### 4. Reproducible Evaluation

- **Old:** Hardcoded seed=42
- **New:** Configurable `--eval_seed` â†’ same seed = same results

---

## ğŸ“– Documentation

For full details, see:
- **User Guide:** `docs/validation_stability.md` (comprehensive)
- **Implementation:** `VALIDATION_STABILITY_IMPLEMENTATION.md` (technical details)

---

## âš™ï¸ All New Flags

### Training Script (`models/train_cape_episodic.py`)

```bash
--val_episodes_per_epoch 200     # Number of val episodes (default: 200)
--fixed_val_episodes             # Use same episodes each epoch (recommended!)
--val_seed 42                    # Seed for episode generation (default: 42)
```

### Evaluation Script (`scripts/eval_cape_checkpoint.py`)

```bash
--eval_seed 123                  # Seed for reproducible evaluation (default: 123)
--num-episodes 200               # Already existed, now with fixed_episodes=True
```

---

## âœ… Verification Tests

### Test 1: Reproducibility

```bash
# Run evaluation twice with same seed
python scripts/eval_cape_checkpoint.py \
    --checkpoint checkpoint_e050.pth \
    --num-episodes 100 \
    --eval_seed 42

# Run again (same command)
python scripts/eval_cape_checkpoint.py \
    --checkpoint checkpoint_e050.pth \
    --num-episodes 100 \
    --eval_seed 42

# Expected: Identical PCK both times
```

### Test 2: Stability

```bash
# Start training and watch first 10 epochs
python models/train_cape_episodic.py \
    --val_episodes_per_epoch 200 \
    --fixed_val_episodes \
    --val_seed 42 \
    --epochs 10

# Expected: Val PCK should vary by <5% between epochs
# Expected: 5-epoch MA should show smooth trend
```

---

## ğŸ“ Pro Tips

### What to Trust During Training

| Metric | Trust Level | Notes |
|--------|-------------|-------|
| **5-epoch MA Val PCK** | â­â­â­â­â­ | Best indicator of real progress |
| **Single-epoch Val PCK** | â­â­â­ | OK if using `--fixed_val_episodes` |
| **Train loss** | â­â­â­â­â­ | Always reliable |
| **Val/Train ratio** | â­â­â­â­ | Good overfitting indicator |

### When to Stop Training

```
âœ… GOOD: Val loss decreasing, PCK increasing
âœ… GOOD: Val/Train ratio < 1.5x (not overfitting)

âš ï¸ WARNING: Val loss flat for 10+ epochs â†’ plateau
âš ï¸ WARNING: Val/Train ratio > 1.5x â†’ overfitting starting

ğŸ›‘ STOP: Val loss increasing for 5+ epochs
ğŸ›‘ STOP: Val/Train ratio > 2.5x â†’ severe overfitting
```

### Debugging High Variance

If you still see large PCK swings even with `--fixed_val_episodes`:

```bash
# 1. Increase validation episodes
--val_episodes_per_epoch 300  # or 400, 500

# 2. Check evaluation variance
python scripts/eval_cape_checkpoint.py \
    --checkpoint checkpoint.pth \
    --num-episodes 200 \
    --eval_seed 1   # Run with different seeds
# Repeat with seeds 2, 3, 4, 5
# If PCK varies by >5%, increase --num-episodes
```

---

## ğŸ‰ Summary

**You can now:**
- âœ… Train with stable validation metrics (no more 30% swings!)
- âœ… Trust the 5-epoch moving average for real progress
- âœ… Evaluate checkpoints reproducibly
- âœ… Compare different models fairly
- âœ… Detect overfitting reliably
- âœ… Make informed decisions about early stopping

**Next steps:**
1. Start a new training run with recommended settings
2. Monitor the 5-epoch MA (ignore single-epoch noise)
3. Evaluate your best checkpoint with 200+ episodes

**Happy training!** ğŸš€

