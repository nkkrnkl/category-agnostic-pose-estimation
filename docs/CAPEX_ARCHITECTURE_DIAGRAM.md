# CapeX Architecture: Visual Diagrams

**Purpose**: Visual representation of CapeX's architecture and our integration strategy

---

## Diagram 1: CapeX Complete Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT DATA                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Support Information:                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Text             â”‚  â”‚ Skeleton         â”‚  â”‚ Visibility Mask â”‚  â”‚
â”‚  â”‚ ["left eye",     â”‚  â”‚ [[0, 2],         â”‚  â”‚ [1, 1, 1, ...]  â”‚  â”‚
â”‚  â”‚  "right eye",    â”‚  â”‚  [1, 2],         â”‚  â”‚                 â”‚  â”‚
â”‚  â”‚  "nose"]         â”‚  â”‚  ...]            â”‚  â”‚                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“                       â†“                      â†“            â”‚
â”‚    (TEXT-BASED âŒ)         (GEOMETRIC âœ…)        (GEOMETRIC âœ…)      â”‚
â”‚                                                                     â”‚
â”‚  Query Information:                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ Query Image [bs, 3, 256, 256]        â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FEATURE EXTRACTION                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Text Branch (âŒ MUST REPLACE):                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ CLIP/BERT    â”‚  â†’   â”‚ L2 Normalize â”‚  â†’   â”‚ Pad to 100   â”‚     â”‚
â”‚  â”‚ Tokenizer    â”‚      â”‚              â”‚      â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â†“                                                           â”‚
â”‚  Text Embeddings: [bs, 100, 512]                                   â”‚
â”‚         â†“                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚ Linear Projection: 512 â†’ 256 â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚         â†“                                                           â”‚
â”‚  Support Embeddings: [bs, 100, 256] â† THIS IS THE KEY TENSOR!      â”‚
â”‚                                                                     â”‚
â”‚  Image Branch (âœ… KEEP):                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Swin-V2      â”‚  â†’   â”‚ FPN/Neck     â”‚  â†’   â”‚ Conv 1x1     â”‚     â”‚
â”‚  â”‚ Backbone     â”‚      â”‚              â”‚      â”‚ 768 â†’ 256    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â†“                                                           â”‚
â”‚  Query Features: [bs, 256, 32, 32]                                 â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRANSFORMER ENCODER (âœ… KEEP)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Flatten image: [bs, 256, 32, 32] â†’ [1024, bs, 256]               â”‚
â”‚  Transpose support: [bs, 100, 256] â†’ [100, bs, 256]               â”‚
â”‚                                                                     â”‚
â”‚  Concatenate: [1024 + 100, bs, 256] = [1124, bs, 256]             â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Multi-Head Self-Attention (3 layers)           â”‚                â”‚
â”‚  â”‚                                                 â”‚                â”‚
â”‚  â”‚ Jointly processes:                              â”‚                â”‚
â”‚  â”‚  - Image features (spatial context)             â”‚                â”‚
â”‚  â”‚  - Support features (keypoint identity)         â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â†“                              â†“                            â”‚
â”‚  Query Embed          Refined Support Embed                        â”‚
â”‚  [1024, bs, 256]      [100, bs, 256]                               â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROPOSAL GENERATOR (âœ… KEEP, geometry-only)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Cross-Attention: Support queries Ã— Image keys                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Q: Refined Support [100, bs, 256]            â”‚                  â”‚
â”‚  â”‚ K, V: Query Embed [1024, bs, 256]            â”‚                  â”‚
â”‚  â”‚                                               â”‚                  â”‚
â”‚  â”‚ Output: Similarity Map [bs, 100, 32, 32]     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â†“                                                           â”‚
â”‚  Soft Argmax:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ For each keypoint:                            â”‚                  â”‚
â”‚  â”‚   Find local maximum in similarity map        â”‚                  â”‚
â”‚  â”‚   Compute weighted average of coordinates     â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â†“                                                           â”‚
â”‚  Initial Proposals: [bs, 100, 2]  â† First coordinate predictions!  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         POSITIONAL ENCODING FROM COORDS (âœ… KEEP, geometry-only)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ SinePositionalEncoding.forward_coordinates() â”‚                  â”‚
â”‚  â”‚                                               â”‚                  â”‚
â”‚  â”‚ Input: [bs, 100, 2] coordinates (in [0,1])   â”‚                  â”‚
â”‚  â”‚                                               â”‚                  â”‚
â”‚  â”‚ Process:                                      â”‚                  â”‚
â”‚  â”‚   x_scaled = x * 2Ï€                           â”‚                  â”‚
â”‚  â”‚   y_scaled = y * 2Ï€                           â”‚                  â”‚
â”‚  â”‚                                               â”‚                  â”‚
â”‚  â”‚   freq[i] = 10000^(2i/256)                    â”‚                  â”‚
â”‚  â”‚                                               â”‚                  â”‚
â”‚  â”‚   pos_x[i] = sin(x_scaled / freq[i])  (even) â”‚                  â”‚
â”‚  â”‚            = cos(x_scaled / freq[i])  (odd)  â”‚                  â”‚
â”‚  â”‚   pos_y[i] = sin(y_scaled / freq[i])  (even) â”‚                  â”‚
â”‚  â”‚            = cos(y_scaled / freq[i])  (odd)  â”‚                  â”‚
â”‚  â”‚                                               â”‚                  â”‚
â”‚  â”‚ Output: [bs, 100, 256] positional embeddings  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           GRAPH TRANSFORMER DECODER (âœ… MOSTLY KEEP)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  For each of 3 decoder layers:                                      â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ LAYER INPUT:                                            â”‚       â”‚
â”‚  â”‚   - tgt: [100, bs, 256] (support features)              â”‚       â”‚
â”‚  â”‚   - memory: [1024, bs, 256] (query image features)      â”‚       â”‚
â”‚  â”‚   - pos: [100, bs, 256] (positional encoding)           â”‚       â”‚
â”‚  â”‚   - skeleton: [[[0,1], [1,2], ...], ...] (edges)        â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                         â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ STEP 1: Self-Attention                                  â”‚       â”‚
â”‚  â”‚   Q = K = V = tgt + pos                                 â”‚       â”‚
â”‚  â”‚   tgt_refined = MultiHeadAttention(Q, K, V)             â”‚       â”‚
â”‚  â”‚   tgt = tgt + tgt_refined  (residual)                   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                         â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ STEP 2: Cross-Attention                                 â”‚       â”‚
â”‚  â”‚   Q = tgt + pos                                          â”‚       â”‚
â”‚  â”‚   K = V = memory + image_pos                             â”‚       â”‚
â”‚  â”‚   tgt_refined = MultiHeadAttention(Q, K, V)             â”‚       â”‚
â”‚  â”‚   tgt = tgt + tgt_refined  (residual)                   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                         â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ STEP 3: FFN with GCN (ğŸ¯ CRITICAL COMPONENT!)           â”‚       â”‚
â”‚  â”‚                                                          â”‚       â”‚
â”‚  â”‚ IF graph_decoder == 'pre':                              â”‚       â”‚
â”‚  â”‚                                                          â”‚       â”‚
â”‚  â”‚   adj = adj_from_skeleton(skeleton, mask)               â”‚       â”‚
â”‚  â”‚   â†“                                                      â”‚       â”‚
â”‚  â”‚   [bs, 2, 100, 100] normalized adjacency                â”‚       â”‚
â”‚  â”‚                                                          â”‚       â”‚
â”‚  â”‚   tgt_gcn = GCNLayer(tgt, adj)                          â”‚       â”‚
â”‚  â”‚   â†“                                                      â”‚       â”‚
â”‚  â”‚   [100, bs, 768] graph-aggregated features              â”‚       â”‚
â”‚  â”‚                                                          â”‚       â”‚
â”‚  â”‚   tgt_gcn = ReLU(tgt_gcn)                               â”‚       â”‚
â”‚  â”‚   tgt_gcn = Linear(tgt_gcn)  # 768 â†’ 256                â”‚       â”‚
â”‚  â”‚                                                          â”‚       â”‚
â”‚  â”‚   tgt = tgt + tgt_gcn  (residual)                       â”‚       â”‚
â”‚  â”‚                                                          â”‚       â”‚
â”‚  â”‚ This allows each keypoint to aggregate information      â”‚       â”‚
â”‚  â”‚ from its skeleton neighbors!                             â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                         â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ STEP 4: Coordinate Prediction                           â”‚       â”‚
â”‚  â”‚   delta = MLP(tgt)  # [100, bs, 2]                      â”‚       â”‚
â”‚  â”‚   coords_new = sigmoid(inv_sigmoid(coords_old) + delta) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                         â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ STEP 5: Update Positional Encoding                      â”‚       â”‚
â”‚  â”‚   pos = SinePositionalEncoding(coords_new)              â”‚       â”‚
â”‚  â”‚   (Used in next decoder layer)                          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                     â”‚
â”‚  Repeat for layers 2 and 3...                                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Final Predictions: [bs, 100, 2]                                   â”‚
â”‚  - Normalized coordinates (in [0, 1])                               â”‚
â”‚  - Refined through 3 decoder layers                                 â”‚
â”‚  - Graph-aware (neighbors influence each other)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Diagram 2: Text-Based vs Geometry-Based Support Encoding

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CapeX (Text-Based) âŒ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Keypoint Descriptions:                                              â”‚
â”‚    ["front left leg", "front right leg", "rear left leg", ...]      â”‚
â”‚                                                                      â”‚
â”‚         â†“ [CLIP Text Encoder]                                       â”‚
â”‚                                                                      â”‚
â”‚  Text Embeddings (CLIP ViT-B/32):                                   â”‚
â”‚    [0.21, -0.45, ..., 0.33]  â† 512-dim vector                       â”‚
â”‚    [0.19, -0.43, ..., 0.31]                                         â”‚
â”‚    [-0.12, 0.67, ..., -0.22]                                        â”‚
â”‚    ...                                                               â”‚
â”‚                                                                      â”‚
â”‚         â†“ [L2 Normalize + Pad]                                      â”‚
â”‚                                                                      â”‚
â”‚  Padded Text Embeddings: [bs, 100, 512]                             â”‚
â”‚                                                                      â”‚
â”‚         â†“ [Linear Projection: 512 â†’ 256]                            â”‚
â”‚                                                                      â”‚
â”‚  Support Embeddings: [bs, 100, 256] âœ¨                              â”‚
â”‚                                                                      â”‚
â”‚  Properties:                                                         â”‚
â”‚    âœ… Semantic: "leg" has similar embedding across categories        â”‚
â”‚    âœ… Disambiguates: "left" vs "right" encoded differently           â”‚
â”‚    âœ… Pre-trained: CLIP provides transfer learning                   â”‚
â”‚    âŒ Requires text: Not geometry-only                               â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              vs

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Our Approach (Geometry-Based) âœ…                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Support Coordinates:                                                â”‚
â”‚    [[0.3, 0.2], [0.7, 0.2], [0.5, 0.5], ...]                       â”‚
â”‚                                                                      â”‚
â”‚  Skeleton Edges:                                                     â”‚
â”‚    [[0, 2], [1, 2], [0, 3], ...]                                    â”‚
â”‚                                                                      â”‚
â”‚         â†“ [OPTION A: Coordinate MLP]                                â”‚
â”‚                                                                      â”‚
â”‚  Coordinate Features:                                                â”‚
â”‚    MLP([0.3, 0.2]) â†’ [0.12, -0.34, ..., 0.56]  â† 256-dim           â”‚
â”‚    MLP([0.7, 0.2]) â†’ [0.15, -0.31, ..., 0.52]                      â”‚
â”‚    ...                                                               â”‚
â”‚                                                                      â”‚
â”‚         â†“ [OPTION B: Add Positional Encoding] â­ RECOMMENDED         â”‚
â”‚                                                                      â”‚
â”‚  Positional Features:                                                â”‚
â”‚    SinePosEnc([0.3, 0.2]) â†’ [0.95, 0.31, ..., 0.02]  â† 256-dim     â”‚
â”‚    SinePosEnc([0.7, 0.2]) â†’ [0.76, 0.65, ..., 0.01]                â”‚
â”‚    ...                                                               â”‚
â”‚                                                                      â”‚
â”‚  Combined:                                                           â”‚
â”‚    coord_feat + pos_feat â†’ [bs, 100, 256]                           â”‚
â”‚                                                                      â”‚
â”‚         â†“ [OPTION C: Add Graph Pre-Encoding] (Optional)             â”‚
â”‚                                                                      â”‚
â”‚  Graph-Aggregated Features:                                          â”‚
â”‚    adj = adj_from_skeleton(skeleton)                                â”‚
â”‚    graph_feat = GNN(coord_feat, adj)                                â”‚
â”‚                                                                      â”‚
â”‚  Final:                                                              â”‚
â”‚    support_embed = coord_feat + pos_feat + graph_feat               â”‚
â”‚                                                                      â”‚
â”‚  Support Embeddings: [bs, 100, 256] âœ¨                              â”‚
â”‚                                                                      â”‚
â”‚  Properties:                                                         â”‚
â”‚    âœ… Geometric: Based on coordinates + topology                     â”‚
â”‚    âš ï¸ Less semantic: Can't distinguish "leg" concept                â”‚
â”‚    âš ï¸ Symmetry: Might confuse left/right                            â”‚
â”‚    âœ… No text: Purely geometry-based                                 â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Difference**: Text embeddings capture **semantic identity**, geometric embeddings capture **spatial position + topology**.

---

## Diagram 3: Graph Convolution in Decoder

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECODER LAYER (with GCN)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Input:                                                              â”‚
â”‚    tgt: [100, bs, 256] â† keypoint features                          â”‚
â”‚    skeleton: [[[0,1], [1,2], [2,3], ...], ...]                      â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ BUILD ADJACENCY MATRIX                             â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ Example skeleton: [[0,1], [1,2], [2,0]]  (triangle)â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ Adjacency (before normalization):                  â”‚             â”‚
â”‚  â”‚     0   1   2                                       â”‚             â”‚
â”‚  â”‚ 0 â”‚ 0   1   1 â”‚                                     â”‚             â”‚
â”‚  â”‚ 1 â”‚ 1   0   1 â”‚                                     â”‚             â”‚
â”‚  â”‚ 2 â”‚ 1   1   0 â”‚                                     â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ Normalize (row-sum = 1):                            â”‚             â”‚
â”‚  â”‚     0    1    2                                      â”‚             â”‚
â”‚  â”‚ 0 â”‚ 0   0.5  0.5 â”‚  â† Node 0 connects to 1 and 2   â”‚             â”‚
â”‚  â”‚ 1 â”‚ 0.5  0   0.5 â”‚  â† Node 1 connects to 0 and 2   â”‚             â”‚
â”‚  â”‚ 2 â”‚ 0.5 0.5   0  â”‚  â† Node 2 connects to 0 and 1   â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ Dual-channel:                                       â”‚             â”‚
â”‚  â”‚   Channel 0: Identity (self-loops)                  â”‚             â”‚
â”‚  â”‚   Channel 1: Neighbors (skeleton edges)             â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ Output: adj [bs, 2, 100, 100]                       â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                         â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ GCN LAYER (graph_decoder='pre')                    â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ 1. Conv1d: [100, bs, 256] â†’ [100, bs, 768*2]       â”‚             â”‚
â”‚  â”‚    (Generates 2 transformations for 2 channels)     â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ 2. Reshape: [100, bs, 1536] â†’ [bs, 2, 768, 100]    â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ 3. Graph aggregation (Einstein sum):                â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚    x_out[v] = Î£_k Î£_u (W_k * x[u] * adj[k, v, u])  â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚    Where:                                            â”‚             â”‚
â”‚  â”‚      k âˆˆ {0=self, 1=neighbors}                      â”‚             â”‚
â”‚  â”‚      u âˆˆ all keypoints                              â”‚             â”‚
â”‚  â”‚      adj[k, v, u] = adjacency weight                â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚    In plain English:                                 â”‚             â”‚
â”‚  â”‚      Each keypoint aggregates features from:         â”‚             â”‚
â”‚  â”‚        - Itself (channel 0)                          â”‚             â”‚
â”‚  â”‚        - Its graph neighbors (channel 1)             â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ 4. Apply ReLU activation                            â”‚             â”‚
â”‚  â”‚                                                     â”‚             â”‚
â”‚  â”‚ Output: [100, bs, 768]                              â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                         â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ LINEAR LAYER                                        â”‚             â”‚
â”‚  â”‚   [100, bs, 768] â†’ [100, bs, 256]                   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                         â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ RESIDUAL CONNECTION                                 â”‚             â”‚
â”‚  â”‚   tgt = tgt_original + tgt_gcn                      â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                         â†“                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ COORDINATE PREDICTION                               â”‚             â”‚
â”‚  â”‚   delta = MLP(tgt)  # [100, bs, 2]                  â”‚             â”‚
â”‚  â”‚   coords = sigmoid(inv_sigmoid(old_coords) + delta) â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                         â†“                                            â”‚
â”‚  Updated coordinates: [bs, 100, 2]                                  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ UPDATE POSITIONAL ENCODING for next layer           â”‚             â”‚
â”‚  â”‚   pos = SinePositionalEncoding(coords)              â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Effect of GCN**: 
- **Without GCN**: Each keypoint is refined independently
- **With GCN**: Connected keypoints share information (e.g., shoulder influences elbow)

---

## Diagram 4: Adjacency Matrix Example

**Skeleton**: Human body (simplified)
```
Keypoints:
  0: Head
  1: Left shoulder
  2: Right shoulder  
  3: Left elbow
  4: Right elbow

Edges:
  [0, 1]: Head â†’ Left shoulder
  [0, 2]: Head â†’ Right shoulder
  [1, 3]: Left shoulder â†’ Left elbow
  [2, 4]: Right shoulder â†’ Right elbow
```

**Adjacency Matrix** (Channel 1 - neighbors):
```
       0     1     2     3     4
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 0 â”‚ 0    0.5  0.5   0     0    â”‚  â† Head connects to both shoulders
 1 â”‚ 0.5   0    0   0.5    0    â”‚  â† Left shoulder â†’ Head, Left elbow
 2 â”‚ 0.5   0    0    0    0.5   â”‚  â† Right shoulder â†’ Head, Right elbow
 3 â”‚  0   0.5   0    0     0    â”‚  â† Left elbow â†’ Left shoulder only
 4 â”‚  0    0   0.5   0     0    â”‚  â† Right elbow â†’ Right shoulder only
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**After GCN Layer**:
```
Left shoulder's features (row 1) become:
  new_feat[1] = W_self * feat[1] * 1.0           (self)
              + W_neighbor * feat[0] * 0.5       (head)
              + W_neighbor * feat[3] * 0.5       (left elbow)
              
This means: Left shoulder is now aware of head position and left elbow position!
```

---

## Diagram 5: Our Hybrid Architecture (Proposed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GEOMETRIC SUPPORT ENCODER (NEW)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Input: Support coords [bs, N, 2] + Skeleton edges                  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Coordinate   â”‚     â”‚ Positional       â”‚     â”‚ Graph          â”‚  â”‚
â”‚  â”‚ MLP          â”‚     â”‚ Encoding (Sine)  â”‚     â”‚ Pre-Encoding   â”‚  â”‚
â”‚  â”‚              â”‚     â”‚                  â”‚     â”‚ (GNN)          â”‚  â”‚
â”‚  â”‚ [N,2]â†’[N,256]â”‚     â”‚ [N,2]â†’[N,256]    â”‚     â”‚ [N,256]â†’[N,256]â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†“                      â†“                        â†“            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                              â†“ (Sum)                                 â”‚
â”‚                   Support Embeddings [bs, N, 256]                    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRANSFORMER ENCODER (from CapeX, keep as-is)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Joint encoding of support + query image features                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PROPOSAL GENERATOR (from CapeX, keep as-is)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Cross-attention â†’ Initial coordinate proposals                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        GRAPH TRANSFORMER DECODER (from CapeX, with GCN)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Iterative refinement with graph-conditioned FFN                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       SEQUENCE GENERATOR (from our Raster2Seq, keep!)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Autoregressive token generation (optional, can also use direct     â”‚
â”‚  coordinate regression like CapeX)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                    Final Predictions [bs, N, 2]
```

**Hybrid Benefits**:
- âœ… Geometric support encoding (no text needed)
- âœ… Graph-aware refinement (CapeX's GCN)
- âœ… Sequential structure (our Raster2Seq)
- âœ… Positional encoding (better generalization)

---

## Diagram 6: Information Flow (Detailed)

```
Support Coordinates [bs, 17, 2]         Query Image [bs, 3, 256, 256]
         â”‚                                         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
         â†“                 â†“                       â†“
    Coord MLP      Sine Pos Enc             Swin Backbone
         â”‚                 â”‚                       â”‚
    [bs,17,256]      [bs,17,256]            [bs,768,32,32]
         â”‚                 â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
                  â†“ (Sum)                          â†“
          [bs,17,256]                      [bs,256,32,32]
                  â”‚                                â”‚
                  â”‚                                â”‚
         Support Embed                     Query Features
                  â”‚                                â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ JOINT ENCODER       â”‚
                    â”‚ (Self-Attention)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â†“                         â†“
         Refined Support            Refined Query
         [100, bs, 256]            [1024, bs, 256]
                  â”‚                         â”‚
                  â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚      â”‚
                  â†“      â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ PROPOSAL GENERATOR    â”‚
         â”‚ (Cross-Attention)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
         Initial Proposals [bs, 100, 2]
                  â”‚
                  â”œâ”€â”€â”€â”€â†’ SinePosEnc â†’ pos [bs,100,256]
                  â”‚
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ GRAPH DECODER (Layer 1)       â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚                               â”‚
         â”‚ 1. Self-Attention             â”‚
         â”‚ 2. Cross-Attention            â”‚
         â”‚ 3. FFN with GCN â† ğŸ¯ GRAPH!   â”‚
         â”‚    â”‚                          â”‚
         â”‚    â”œâ”€ adj_from_skeleton()     â”‚
         â”‚    â”‚  [bs, 2, 100, 100]       â”‚
         â”‚    â”‚                          â”‚
         â”‚    â””â”€ GCNLayer(tgt, adj)      â”‚
         â”‚       Aggregates neighbors!   â”‚
         â”‚                               â”‚
         â”‚ 4. Coord prediction           â”‚
         â”‚    coords = sigmoid(...)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”œâ”€â”€â”€â”€â†’ Update pos encoding
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ GRAPH DECODER (Layer 2)       â”‚
         â”‚ ... same structure ...        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ GRAPH DECODER (Layer 3)       â”‚
         â”‚ ... same structure ...        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
         Final Predictions [bs, 100, 2]
```

**Key Insight**: Each decoder layer refines coordinates, and GCN ensures refinements are **graph-consistent** (connected keypoints influence each other).

---

## Diagram 7: Comparison of Graph Decoder Modes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              graph_decoder = None (No Graph)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  FFN:                                                        â”‚
â”‚    tgt â†’ Linear (256â†’768) â†’ ReLU â†’ Linear (768â†’256) â†’ tgt   â”‚
â”‚                                                              â”‚
â”‚  No graph information used!                                  â”‚
â”‚  Each keypoint refined independently.                        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              graph_decoder = 'pre' (Graph Before)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  FFN:                                                        â”‚
â”‚    tgt â†’ GCN (256â†’768, adj) â†’ ReLU â†’ Linear (768â†’256) â†’ tgt â”‚
â”‚          â†‘                                                   â”‚
â”‚          â””â”€ Uses skeleton structure!                         â”‚
â”‚                                                              â”‚
â”‚  Graph aggregation happens early (before activation).        â”‚
â”‚  Features from neighbors are combined before non-linearity.  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              graph_decoder = 'post' (Graph After)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  FFN:                                                        â”‚
â”‚    tgt â†’ Linear (256â†’768) â†’ ReLU â†’ GCN (768â†’256, adj) â†’ tgt â”‚
â”‚                                      â†‘                       â”‚
â”‚                                      â””â”€ Uses skeleton!       â”‚
â”‚                                                              â”‚
â”‚  Graph aggregation happens late (after activation).          â”‚
â”‚  Non-linearity applied before neighbor aggregation.          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              graph_decoder = 'both' (Double Graph)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  FFN:                                                        â”‚
â”‚    tgt â†’ GCNâ‚ (256â†’768, adj) â†’ ReLU â†’ GCNâ‚‚ (768â†’256, adj) â†’ tgtâ”‚
â”‚          â†‘                                â†‘                  â”‚
â”‚          â””â”€ Both layers use skeleton! â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                              â”‚
â”‚  Maximum graph integration.                                  â”‚
â”‚  Neighbors influence each other twice.                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CapeX uses**: `graph_decoder='pre'` in their best configs.

**Our recommendation**: Start with `'pre'`, ablate `None` vs `'pre'` vs `'both'`.

---

## Diagram 8: GCN Aggregation Example

**Scenario**: Predicting "left elbow" position

```
Before GCN:
  Left shoulder feature: [0.2, 0.5, -0.3, ...]
  Left elbow feature: [0.1, 0.3, -0.2, ...]  â† Prediction for this
  Left wrist feature: [0.15, 0.4, -0.1, ...]

Skeleton:
  [1, 3]: Left shoulder â†â†’ Left elbow
  [3, 5]: Left elbow â†â†’ Left wrist

Adjacency (for Left elbow, node 3):
  adj[3, 1] = 0.5  (connected to left shoulder)
  adj[3, 5] = 0.5  (connected to left wrist)
  adj[3, 3] = 0    (no self-loop in neighbor channel)

GCN Computation:
  new_feat[3] = W_self * feat[3] * 1.0              (channel 0: self)
              + W_neighbor * feat[1] * 0.5          (channel 1: shoulder)
              + W_neighbor * feat[5] * 0.5          (channel 1: wrist)
              
After GCN:
  Left elbow feature: [0.12, 0.42, -0.18, ...]
  
  Now contains information from:
    - Its own position
    - Left shoulder position (proximal)
    - Left wrist position (distal)
```

**Result**: The prediction for left elbow is now **context-aware** - it knows where the shoulder and wrist are!

---

## Diagram 9: Integration Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CURRENT STATE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  âœ… Image Encoder (ResNet)                                 â”‚
â”‚  âœ… Deformable Cross-Attention                             â”‚
â”‚  âœ… Raster2Seq Decoder (Token sequences)                   â”‚
â”‚  âœ… Episodic Dataloader                                    â”‚
â”‚  âŒ Support Encoding (NOT IMPLEMENTED)                     â”‚
â”‚  âŒ Graph Encoding (NOT IMPLEMENTED)                       â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: Port Utils                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Create models/graph_utils.py:                             â”‚
â”‚    âœ… adj_from_skeleton()                                  â”‚
â”‚    âœ… GCNLayer                                             â”‚
â”‚    âœ… Unit tests                                           â”‚
â”‚                                                            â”‚
â”‚  Effort: 2-3 hours                                         â”‚
â”‚  Risk: Low (standalone utilities)                          â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: Support Encoding                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Create models/support_encoder.py:                         â”‚
â”‚    âœ… GeometricSupportEncoder                              â”‚
â”‚       - Coordinate MLP                                     â”‚
â”‚       - Positional encoding                                â”‚
â”‚       - (Optional) Graph pre-encoding                      â”‚
â”‚    âœ… Unit tests                                           â”‚
â”‚                                                            â”‚
â”‚  Effort: 4-6 hours                                         â”‚
â”‚  Risk: Medium (new component, needs testing)               â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               PHASE 3: Decoder Integration                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Modify models/cape_model.py:                              â”‚
â”‚    âœ… Add GeometricSupportEncoder to __init__              â”‚
â”‚    âœ… Add GCNLayer to decoder layers                       â”‚
â”‚    âœ… Modify forward() to:                                 â”‚
â”‚       - Encode support geometrically                       â”‚
â”‚       - Pass skeleton to decoder                           â”‚
â”‚       - Apply GCN in FFN                                   â”‚
â”‚    âœ… Add config flag: use_graph_decoder                   â”‚
â”‚                                                            â”‚
â”‚  Effort: 6-8 hours                                         â”‚
â”‚  Risk: Medium-High (integration complexity)                â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               PHASE 4: Dataset Updates                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Modify datasets/mp100_cape.py:                            â”‚
â”‚    âœ… Include 'skeleton' in __getitem__ return             â”‚
â”‚    âœ… Ensure skeleton format: [[[src,dst], ...]]           â”‚
â”‚                                                            â”‚
â”‚  Modify datasets/episodic_sampler.py:                      â”‚
â”‚    âœ… Pass skeleton through in batch collation             â”‚
â”‚                                                            â”‚
â”‚  Effort: 2-3 hours                                         â”‚
â”‚  Risk: Low (simple addition)                               â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 5: Training                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  Train two models:                                         â”‚
â”‚    1. Baseline (use_graph=false)                           â”‚
â”‚    2. With graph (use_graph=true)                          â”‚
â”‚                                                            â”‚
â”‚  Compare:                                                  â”‚
â”‚    - Validation PCK                                        â”‚
â”‚    - Training curves                                       â”‚
â”‚    - Qualitative predictions                               â”‚
â”‚                                                            â”‚
â”‚  Effort: 24-48 hours compute time                          â”‚
â”‚  Risk: Medium (might need debugging)                       â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SUCCESS!                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  âœ… Geometry-only pose estimation working                  â”‚
â”‚  âœ… Graph structure improves predictions                   â”‚
â”‚  âœ… No text dependencies                                   â”‚
â”‚  âœ… Generalizes to unseen categories                       â”‚
â”‚                                                            â”‚
â”‚  Expected PCK: 60-75% on MP-100 validation                 â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Diagram 10: Comparison Table (Detailed)

| Component | CapeX (Original) | CapeX (What We Can Use) | Our Current | After Integration |
|-----------|------------------|-------------------------|-------------|-------------------|
| **Support Encoding** | Text (CLIP) [bs,N,512] | âŒ Can't use text | âŒ Not implemented | âœ… Coords+Pos+Graph [bs,N,256] |
| **Graph Encoding** | GCN in decoder FFN | âœ… **USE THIS!** | âŒ None | âœ… GCN in decoder |
| **Adjacency Matrix** | `adj_from_skeleton()` | âœ… **USE THIS!** | âŒ None | âœ… Ported function |
| **Positional Encoding** | Sinusoidal (2D coords) | âœ… **USE THIS!** | â“ Check ours | âœ… Use CapeX version |
| **Prediction Type** | Set (parallel) | âš ï¸ Optional | Sequence (autoregressive) | Keep sequence |
| **Coordinate Format** | Direct regression | âš ï¸ Optional | Discrete tokens | Keep tokens |
| **Image Backbone** | Swin-V2 | âš ï¸ Optional | ResNet-50 | Keep ResNet |
| **Decoder** | DETR-style | âœ… Pattern reusable | Transformer | Add GCN to ours |

**Legend**:
- âœ… Direct copy/use
- âš ï¸ Can use but need to adapt
- âŒ Can't use (text-dependent or not needed)
- â“ Check our implementation

---

## Diagram 11: 80/20 Rule - What Matters Most

```
   Impact on Performance
        â†‘
   100% â”‚
        â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                              â”‚ Text Embedding â”‚  â† CapeX uses this
        â”‚                              â”‚ (90% impact)   â”‚     (We can't!)
        â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    75% â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚ Graph      â”‚  â† We CAN use this!
        â”‚              â”‚ Encoding   â”‚     (Expected +10-15%)
        â”‚              â”‚ (GCN)      â”‚
        â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    50% â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  â”‚Positionalâ”‚  â† We CAN use this!
        â”‚  â”‚Encoding  â”‚     (Expected +5-10%)
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    25% â”‚  
        â”‚  â”Œâ”€â”€â”€â”€â”€â”
        â”‚  â”‚Otherâ”‚
        â”‚  â””â”€â”€â”€â”€â”€â”˜
        â”‚
     0% â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
        Component

Conclusion: We can capture ~20-25% of CapeX's benefit by using graph + positional encoding.
            The remaining ~70% comes from text (which we can't use).
            This is acceptable for a geometry-only approach!
```

---

## Diagram 12: Decision Tree

```
START: Do you want geometry-only pose estimation?
   â”‚
   â”œâ”€ NO â†’ Use CapeX as-is (with text)
   â”‚       Performance: 88% PCK
   â”‚       Effort: Minimal (use pretrained)
   â”‚
   â””â”€ YES â†’ Proceed
          â”‚
          â”œâ”€ Can you use support images?
          â”‚  â”‚
          â”‚  â”œâ”€ YES â†’ Traditional CAPE (not CapeX)
          â”‚  â”‚         Use image features instead of text
          â”‚  â”‚         Performance: ~75-80% PCK (estimated)
          â”‚  â”‚
          â”‚  â””â”€ NO â†’ Use support coordinates only
          â”‚           â”‚
          â”‚           â””â”€ Adopt CapeX graph encoding!
          â”‚              â”‚
          â”‚              â”œâ”€ OPTION 1: Minimal (GCN only)
          â”‚              â”‚  Effort: 1 week
          â”‚              â”‚  Performance: 50-60% PCK
          â”‚              â”‚
          â”‚              â”œâ”€ OPTION 2: Moderate (GCN + Support Encoder) â­
          â”‚              â”‚  Effort: 3-4 weeks
          â”‚              â”‚  Performance: 60-75% PCK
          â”‚              â”‚  â† RECOMMENDED
          â”‚              â”‚
          â”‚              â””â”€ OPTION 3: Maximal (Full CapeX)
          â”‚                 Effort: 6-8 weeks
          â”‚                 Performance: 65-80% PCK
          â”‚                 Risk: High (major refactor)
```

---

## Diagram 13: What Breaks Symmetry?

**Problem**: Given two symmetric keypoints (e.g., left eye, right eye), how do we distinguish them?

### CapeX Solution (Text-Based)

```
"left eye" â†’ CLIP â†’ [0.21, -0.45, ..., 0.33]
                    â†“
            Distinct embedding

"right eye" â†’ CLIP â†’ [0.19, -0.43, ..., 0.31]
                     â†“
            Different embedding (due to "left" vs "right" in text)

Result: Model knows which is which because embeddings are different.
```

### Our Challenge (Geometry-Based)

```
Left eye coord: [0.3, 0.2]
                    â†“
               MLP â†’ [0.12, -0.34, ..., 0.56]
                    â†“
               Sine pos enc â†’ [0.95, 0.31, ..., 0.02]

Right eye coord: [0.7, 0.2]
                    â†“
               MLP â†’ [0.15, -0.31, ..., 0.52]
                    â†“
               Sine pos enc â†’ [0.76, 0.65, ..., 0.01]

Result: Embeddings are different (due to x-coordinate difference),
        but model doesn't "know" which is "left" vs "right" semantically.
```

**Potential Solutions**:

**Solution 1: Spatial Prior (Weak)**
```
Assume: left < right in x-coordinate
Problem: Breaks with rotation, perspective, mirror images
```

**Solution 2: Graph Context (Better)**
```
Left eye connects to:     Right eye connects to:
  - Nose (center)           - Nose (center)
  - Left ear (left side)    - Right ear (right side)
  
Graph neighborhood is different â†’ model can learn to distinguish
```

**Solution 3: Relative Positioning (Best)**
```
Encode relative positions to skeleton root:
  Left eye: (-0.2, 0.0) relative to nose
  Right eye: (+0.2, 0.0) relative to nose
  
Signed offsets provide directionality!
```

**CapeX doesn't need any of these because text handles it!**

---

## Diagram 14: Loss Functions Comparison

### CapeX Losses

```python
# 1. L1 Loss (coordinate regression)
loss_l1 = F.l1_loss(pred_coords, gt_coords, reduction='none')
loss_l1 = (loss_l1 * visibility_mask).mean()

# 2. Heatmap Loss (spatial distribution)
pred_heatmap = generate_heatmap(pred_coords)
gt_heatmap = generate_heatmap(gt_coords)
loss_heatmap = F.mse_loss(pred_heatmap, gt_heatmap)

# 3. Proposal Loss (initial localization)
loss_proposal = F.l1_loss(initial_proposals, gt_coords)

# Total
loss = 5.0 * loss_l1 + 1.0 * loss_heatmap + 2.0 * loss_proposal
```

### Our Current Losses

```python
# 1. Token Cross-Entropy (sequence generation)
loss_seq = F.cross_entropy(
    logits.view(-1, vocab_size),
    target_tokens.view(-1),
    ignore_index=pad_token_id
)

# 2. Coordinate MSE (after detokenization)
pred_coords = detokenize(predicted_tokens)
loss_coord = F.mse_loss(pred_coords, gt_coords)

# Total
loss = loss_seq + 0.1 * loss_coord
```

**Can we use both?**
- âœ… YES! Use CapeX's coordinate losses for support encoding training
- âœ… Keep our sequence losses for final prediction
- This is a **multi-task learning** setup

---

## Diagram 15: Training Flow Comparison

### CapeX Training

```
Epoch:
  For each batch (support text + query image):
    1. Encode text â†’ support embeddings
    2. Extract query image features
    3. Joint encoding (transformer encoder)
    4. Generate initial proposals (cross-attention)
    5. Refine with graph decoder (3 layers with GCN)
    6. Compute loss (L1 + heatmap + proposal)
    7. Backprop and update weights
    
  Validation:
    - Evaluate on unseen categories (category-agnostic)
    - Metric: PCK (Percentage of Correct Keypoints)
    - Early stopping if PCK doesn't improve
```

### Our Training (After Integration)

```
Epoch:
  For each episode (support coords + skeleton + query image):
    1. Encode coords â†’ support embeddings (GEOMETRIC)
    2. Extract query image features (SAME)
    3. Joint encoding (transformer encoder) (SAME)
    4. Generate initial proposals (SAME)
    5. Refine with graph decoder (SAME, with GCN!)
    6. Generate token sequences (OUR ADDITION)
    7. Compute loss (sequence + coordinate) (HYBRID)
    8. Backprop and update weights
    
  Validation:
    - Same as CapeX (unseen categories, PCK metric)
```

**Difference**: We add sequence generation on top of CapeX's architecture.

---

## Diagram 16: Module Dependency Graph

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ GeometricSupport     â”‚
                   â”‚ Encoder (NEW)        â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ uses
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Coordinate MLP    â”‚  â”‚ SinePositional    â”‚
         â”‚ (NEW)             â”‚  â”‚ Encoding (PORT)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ optional
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Graph Pre-Encoder  â”‚
         â”‚ (GNN) (NEW)        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ uses
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ GCNLayer (PORT)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ uses
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ adj_from_skeleton  â”‚
         â”‚ (PORT)             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Legend:
  PORT = Copy from CapeX
  NEW = Implement ourselves
  
Dependencies:
  GeometricSupportEncoder
    â”œâ”€ requires: CoordinateMLP (trivial to implement)
    â”œâ”€ requires: SinePositionalEncoding (port from CapeX)
    â””â”€ optional: GraphPreEncoder
                   â””â”€ requires: GCNLayer (port from CapeX)
                                â””â”€ requires: adj_from_skeleton (port from CapeX)
```

**Bottom line**: Only ~80-120 lines of code to port!

---

## Diagram 17: Graph Convolution Mathematics

**Standard GCN Formula**:
```
h_v^(l+1) = Ïƒ( Î£_{u âˆˆ N(v)} (1 / âˆš(deg(v) * deg(u))) * W^(l) * h_u^(l) )

Where:
  h_v = features of vertex v
  N(v) = neighbors of v
  deg(v) = degree of v
  W = learnable weight matrix
  Ïƒ = activation (ReLU)
```

**CapeX's GCN Implementation** (simplified):
```
For each vertex v:
  
  Channel 0 (self-loop):
    self_feat = W_self * h_v
  
  Channel 1 (neighbors):
    neighbor_feat = Î£_{u âˆˆ N(v)} (W_neighbor * h_u * adj[v, u])
    
    Where adj[v, u] = 1 / |N(v)| if u is neighbor of v
                    = 0 otherwise
  
  Output:
    h_v_new = self_feat + neighbor_feat
    h_v_new = ReLU(h_v_new)
```

**Dual-Channel Benefit**:
- Self-connection preserves original features (residual-like)
- Neighbor aggregation adds context
- Separate weights for each (more expressive)

**Why row-normalize?**
- Ensures gradients don't explode
- Degrees vary (some keypoints have many edges, some have few)
- Normalization makes aggregation scale-invariant

---

## Diagram 18: Skeleton Topology Examples

**Animal (Quadruped)**:
```
       0 (head)
       â”‚
   â”Œâ”€â”€â”€â”¼â”€â”€â”€â”
   â”‚   â”‚   â”‚
   1   2   3  (neck, left ear, right ear)
   â”‚
â”Œâ”€â”€â”´â”€â”€â”¬â”€â”€â”´â”€â”€â”
â”‚     â”‚     â”‚
4     5     6  (left shoulder, torso, right shoulder)
â”‚           â”‚
7           8  (left elbow, right elbow)
â”‚           â”‚
9          10  (left paw, right paw)
```

**Skeleton edges**:
```python
animal_skeleton = [
    [0, 1], [0, 2], [0, 3],  # Head â†’ neck, ears
    [1, 4], [1, 5], [1, 6],  # Neck â†’ shoulders, torso
    [4, 7], [6, 8],          # Shoulders â†’ elbows
    [7, 9], [8, 10]          # Elbows â†’ paws
]
```

**Adjacency visualization**:
```
Node 7 (left elbow) has neighbors: {4 (left shoulder)}
  â†’ GCN aggregates features from shoulder
  â†’ Helps predict elbow position relative to shoulder!

Node 1 (neck) has neighbors: {0 (head), 4 (left shoulder), 5 (torso), 6 (right shoulder)}
  â†’ GCN aggregates from many nodes
  â†’ Central node benefits from global context!
```

**Chair**:
```
    0â”€â”€â”€â”€â”€1
    â”‚     â”‚  (left rear leg, right rear leg)
    â”‚     â”‚
    2â”€â”€â”€â”€â”€3
    â”‚     â”‚  (left front leg, right front leg)
    â”‚     â”‚
    4â”€â”€â”€â”€â”€5  (left seat, right seat)
```

**Skeleton edges**:
```python
chair_skeleton = [
    [0, 1], [2, 3], [4, 5],  # Horizontal connections (symmetry)
    [0, 2], [1, 3],          # Vertical connections (legs)
    [2, 4], [3, 5]           # Seat connections
]
```

**Key difference**: Furniture has **grid-like** structure, animals have **tree-like** structure.

**Impact**: Graph encoding should help for both (different topologies, but GCN is topology-agnostic).

---

## Summary Diagrams

### What to Port (Visual Checklist)

```
From CapeX codebase:
    
    ğŸ“ encoder_decoder.py
       â”œâ”€ âœ… adj_from_skeleton()        [~15 lines] Priority 1
       â”œâ”€ âœ… GCNLayer                    [~35 lines] Priority 1
       â”œâ”€ âš ï¸ ProposalGenerator           [~80 lines] Priority 3 (optional)
       â””â”€ âš ï¸ GraphTransformerDecoderLayer[~100 lines] Priority 2 (pattern)
    
    ğŸ“ positional_encoding.py
       â””â”€ âœ… forward_coordinates()       [~30 lines] Priority 1
    
    ğŸ“ capex.py
       â”œâ”€ âŒ extract_text_features()    [~40 lines] DON'T PORT (text)
       â””â”€ âš ï¸ Overall structure           [guidance only]
    
    TOTAL TO PORT: ~80 lines (Priority 1)
    TOTAL IF OPTIONAL: ~260 lines (All priorities)
```

### Integration Complexity

```
Complexity Scale (1-10):

  1-2 â”‚ âœ… Port utility functions (adj_from_skeleton, GCNLayer)
      â”‚    - Standalone, no dependencies
      â”‚    - Copy-paste + test
      â”‚
  3-5 â”‚ âœ… Implement GeometricSupportEncoder
      â”‚    - New component, but straightforward
      â”‚    - MLP + positional encoding
      â”‚
  6-7 â”‚ âš ï¸ Integrate GCN into decoder
      â”‚    - Modify existing code
      â”‚    - Shape compatibility issues possible
      â”‚
  8-9 â”‚ âš ï¸ End-to-end training + debugging
      â”‚    - Convergence issues
      â”‚    - Hyperparameter tuning
      â”‚
   10 â”‚ âŒ Full CapeX architecture replacement
      â”‚    - Major refactor
      â”‚    - High risk
```

**Recommended path**: Tackle 1-2 â†’ 3-5 â†’ 6-7 â†’ 8-9 (skip 10).

---

## Final Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             CAPEX AUDIT: FINAL TAKEAWAYS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  âœ… CAN USE (Geometry-Only):                                   â”‚
â”‚     â€¢ adj_from_skeleton() - Build adjacency matrix             â”‚
â”‚     â€¢ GCNLayer - Graph convolution                             â”‚
â”‚     â€¢ SinePositionalEncoding - Coord â†’ features                â”‚
â”‚     â€¢ Decoder architecture - Transformer + GCN                 â”‚
â”‚     â€¢ Iterative refinement - Multi-layer coordinate updates    â”‚
â”‚                                                                â”‚
â”‚  âŒ CAN'T USE (Text-Dependent):                                â”‚
â”‚     â€¢ CLIP/BERT encoder - Needs text input                     â”‚
â”‚     â€¢ Text projection - Converts text â†’ embeddings             â”‚
â”‚     â€¢ Keypoint descriptions - Semantic labels                  â”‚
â”‚                                                                â”‚
â”‚  ğŸ”§ MUST IMPLEMENT (Replacements):                             â”‚
â”‚     â€¢ GeometricSupportEncoder - Coords â†’ embeddings            â”‚
â”‚     â€¢ Symmetry handling - Spatial/graph disambiguation         â”‚
â”‚                                                                â”‚
â”‚  ğŸ“Š EXPECTED PERFORMANCE:                                      â”‚
â”‚     â€¢ CapeX with text: 88.81% PCK                              â”‚
â”‚     â€¢ Ours without text: 60-75% PCK (estimated)                â”‚
â”‚     â€¢ Gap: Acceptable for geometry-only constraint             â”‚
â”‚                                                                â”‚
â”‚  â±ï¸ EFFORT:                                                     â”‚
â”‚     â€¢ Minimal (GCN only): 1 week                               â”‚
â”‚     â€¢ Moderate (GCN + Support): 3-4 weeks â­ RECOMMENDED       â”‚
â”‚     â€¢ Maximal (Full CapeX): 6-8 weeks                          â”‚
â”‚                                                                â”‚
â”‚  ğŸ¯ RECOMMENDATION:                                             â”‚
â”‚     Adopt CapeX's graph encoding with moderate integration.    â”‚
â”‚     Keep our sequence generation, add geometric support encoderâ”‚
â”‚     and GCN layers. Expected ROI: High value, manageable risk. â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**End of Architecture Diagrams**

